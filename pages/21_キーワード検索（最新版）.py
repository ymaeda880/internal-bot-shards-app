# pages/20_ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢.py
# ------------------------------------------------------------
# ğŸ” meta.jsonl æ¨ªæ–­æ¤œç´¢ + ï¼ˆä»»æ„ï¼‰OpenAI ç”Ÿæˆè¦ç´„ï¼ˆè‡ªå‹•ãƒ»ã‚¹ãƒ”ãƒŠãƒ¼ä»˜ãï¼‰
# - è¦ç´„ã¯æ¤œç´¢çµæœè¡¨ç¤ºã¨åŒã˜å®Ÿè¡Œå†…ã§è‡ªå‹•ç”Ÿæˆï¼ˆãƒœã‚¿ãƒ³ãªã—ï¼‰
# - ç”Ÿæˆä¸­ã¯ã‚¹ãƒ”ãƒŠãƒ¼è¡¨ç¤ºï¼ˆOpenAIå®Ÿè¡Œï¼ãƒ­ãƒ¼ã‚«ãƒ«æŠ½å‡ºï¼‰
# - å¤±æ•—/æœªè¨­å®šæ™‚ã¯ãƒ­ãƒ¼ã‚«ãƒ«æŠ½å‡ºã‚µãƒãƒªã‚’å¿…ãšè¡¨ç¤ºï¼ˆç©ºæŒ¯ã‚Šã‚¼ãƒ­ï¼‰
# - ãƒ•ã‚©ãƒ¼ãƒ /äºŒé‡ç¢ºèª/ rerun / stop ã‚’ä½¿ç”¨ã›ãšâ€œæˆ»ã‚‹â€å•é¡Œã‚’æ ¹çµ¶ï¼ˆæ¤œç´¢ã®ã‚¬ãƒ¼ãƒ‰ä»¥å¤–ï¼‰
# - æ—¢å­˜ã® data/vectorstore/{openai,local} é…ä¸‹ã® meta.jsonl ã‚’èµ°æŸ»
# ------------------------------------------------------------
from __future__ import annotations
from pathlib import Path
from typing import List, Dict, Iterable, Any
import re, json, os, unicodedata, traceback

import pandas as pd
import streamlit as st

# ï¼ˆä»»æ„ï¼‰OpenAIï¼šã‚­ãƒ¼ãŒç„¡ãã¦ã‚‚å‹•ãã¾ã™ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«æŠ½å‡ºã‚µãƒãƒªã«è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
try:
    from openai import OpenAI
    _HAS_OPENAI = True
except Exception:
    _HAS_OPENAI = False

# ============== ãƒ‘ã‚¹ ==============
APP_ROOT = Path(__file__).resolve().parents[1]
DATA_DIR = APP_ROOT / "data"
VS_ROOT  = DATA_DIR / "vectorstore"

# ============== åŸºæœ¬UI ==============
st.set_page_config(page_title="20 ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆmetaæ¨ªæ–­ï¼‰", page_icon="ğŸ”", layout="wide")
st.title("ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆmeta.jsonl æ¨ªæ–­ï¼‰")

# ============== æ—¥æœ¬èªæ­£è¦åŒ– & ãƒ†ã‚­ã‚¹ãƒˆãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ==============
CJK = r"\u3040-\u309F\u30A0-\u30FF\uFF65-\uFF9F\u4E00-\u9FFF\u3400-\u4DBF"
PUNC = r"ã€ã€‚ãƒ»ï¼Œï¼ï¼ï¼Ÿï¼šï¼›ï¼ˆï¼‰ï¼»ï¼½ï½›ï½ã€Œã€ã€ã€ã€ˆã€‰ã€Šã€‹ã€ã€‘"
_cjk_cjk_space = re.compile(fr"(?<=[{CJK}])\s+(?=[{CJK}])")
_space_before_punc = re.compile(fr"\s+(?=[{PUNC}])")
_space_after_open = re.compile(fr"(?<=[ï¼ˆï¼»ï½›ã€Œã€ã€ˆã€Šã€])\s+")
_space_before_close = re.compile(fr"\s+(?=[ï¼‰ï¼½ï½ã€ã€ã€‰ã€‹ã€‘])")
_multi_space = re.compile(r"[ \t\u3000]+")

def normalize_ja_text(s: str) -> str:
    s = unicodedata.normalize("NFKC", s or "")
    s = _cjk_cjk_space.sub("", s)
    s = _space_before_punc.sub("", s)
    s = _space_after_open.sub("", s)
    s = _space_before_close.sub("", s)
    s = _multi_space.sub(" ", s)
    return s.strip()

def strip_html(s: str) -> str:
    return re.sub(r"<[^>]+>", "", s or "")

def make_snippet(text: str, pats: List[re.Pattern], total_len: int = 240) -> str:
    s_pos, e_pos = 0, 0
    for p in pats:
        m = p.search(text)
        if m:
            s_pos, e_pos = m.start(), m.end()
            break
    if e_pos == 0:
        s_pos, e_pos = 0, min(len(text), total_len)
    margin = total_len // 2
    left = max(0, s_pos - margin)
    right = min(len(text), e_pos + margin)
    snippet = text[left:right]
    for p in pats:
        try:
            snippet = p.sub(lambda m: f"<mark>{m.group(0)}</mark>", snippet)
        except re.error:
            pass
    if left > 0:
        snippet = "â€¦" + snippet
    if right < len(text):
        snippet = snippet + "â€¦"
    return snippet

# ============== ãƒˆãƒ¼ã‚¯ãƒ³è¦‹ç©ã‚Šï¼ˆtiktokenãŒç„¡ã‘ã‚Œã°æ¦‚ç®—ï¼‰ ==============
def _encoding_for(model_hint: str):
    try:
        import tiktoken
        try:
            return tiktoken.encoding_for_model(model_hint)
        except Exception:
            return tiktoken.get_encoding("cl100k_base")
    except Exception:
        return None

def count_tokens(text: str, model_hint: str = "gpt-5-mini") -> int:
    enc = _encoding_for(model_hint)
    if enc is None:
        return max(1, int(len(text or "") / 4))
    try:
        return len(enc.encode(text or ""))
    except Exception:
        return max(1, int(len(text or "") / 4))

def truncate_by_tokens(text: str, max_tokens: int, model_hint: str = "gpt-5-mini") -> str:
    enc = _encoding_for(model_hint)
    if enc is None:
        max_chars = max(100, max_tokens * 4)
        return (text or "")[:max_chars]
    try:
        toks = enc.encode(text or "")
        if len(toks) <= max_tokens:
            return text or ""
        return enc.decode(toks[:max_tokens])
    except Exception:
        max_chars = max(100, max_tokens * 4)
        return (text or "")[:max_chars]

def is_gpt5(model_name: str) -> bool:
    return (model_name or "").lower().startswith("gpt-5")

# ============== JSONL ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ ==============
def iter_jsonl(path: Path) -> Iterable[Dict]:
    if not path.exists():
        return
    with path.open("r", encoding="utf-8") as f:
        for line in f:
            s = line.strip()
            if not s:
                continue
            try:
                yield json.loads(s)
            except Exception:
                continue

# ============== ã‚µã‚¤ãƒ‰ãƒãƒ¼ ==============
with st.sidebar:
    st.header("æ¤œç´¢å¯¾è±¡")
    backend = st.radio("ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰", ["openai", "local"], index=0, horizontal=True)
    base_dir = VS_ROOT / backend
    if not base_dir.exists():
        st.error(f"vectorstore/{backend} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã« 03 ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    shard_dirs = sorted([p for p in base_dir.iterdir() if p.is_dir()])
    shard_ids = [p.name for p in shard_dirs]
    sel_shards = st.multiselect("å¯¾è±¡ã‚·ãƒ£ãƒ¼ãƒ‰", shard_ids, default=shard_ids)

    st.divider()
    st.subheader("çµã‚Šè¾¼ã¿ï¼ˆä»»æ„ï¼‰")
    year_min = st.number_input("å¹´ï¼ˆä¸‹é™ï¼‰", value=0, step=1, help="0 ã§ç„¡åŠ¹")
    year_max = st.number_input("å¹´ï¼ˆä¸Šé™ï¼‰", value=9999, step=1, help="9999 ã§ç„¡åŠ¹")
    file_filter = st.text_input("ãƒ•ã‚¡ã‚¤ãƒ«åãƒ•ã‚£ãƒ«ã‚¿ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰", value="").strip()

    st.divider()
    st.subheader("è¡¨ç¤ºè¨­å®š")
    max_rows = st.number_input("æœ€å¤§è¡¨ç¤ºä»¶æ•°", min_value=50, max_value=5000, value=500, step=50)
    snippet_len = st.slider("ã‚¹ãƒ‹ãƒšãƒƒãƒˆé•·ï¼ˆå‰å¾Œåˆè¨ˆï¼‰", min_value=80, max_value=800, value=240, step=20)
    show_cols = st.multiselect(
        "è¡¨ç¤ºã‚«ãƒ©ãƒ ",
        ["file","year","page","shard_id","chunk_id","chunk_index","score","text"],
        default=["file","year","page","shard_id","score","text"]
    )

    st.divider()
    st.subheader("ğŸ§  ç”Ÿæˆã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    # secrets.toml å„ªå…ˆã€ãªã‘ã‚Œã°ç’°å¢ƒå¤‰æ•°
    def _get_openai_key() -> str | None:
        try:
            return (
                st.secrets.get("OPENAI_API_KEY")
                or (st.secrets.get("openai") or {}).get("api_key")
                or os.getenv("OPENAI_API_KEY")
            )
        except Exception:
            return os.getenv("OPENAI_API_KEY")
    OPENAI_API_KEY = _get_openai_key()

    gen_enabled = st.checkbox("ãƒ’ãƒƒãƒˆè¦ç´„ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹", value=True)
    model = st.selectbox("ãƒ¢ãƒ‡ãƒ«", ["gpt-5-mini", "gpt-5", "gpt-4o-mini", "gpt-4o", "gpt-4.1-mini"], index=0)
    temperature = 1.0 if is_gpt5(model) else st.slider("temperature", 0.0, 1.0, 0.2, 0.05)
    max_tokens = st.slider("å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ä¸Šé™", 128, 32000, 2000, 128)
    topn_snippets = st.slider("è¦ç´„ã«ä½¿ã†ä¸Šä½ã‚¹ãƒ‹ãƒšãƒƒãƒˆæ•°", 5, 200, 30, 5)

    sys_prompt = st.text_area(
        "System Prompt",
        value="ã‚ãªãŸã¯äº‹å®Ÿã«å¿ å®Ÿãªãƒªã‚µãƒ¼ãƒã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ ¹æ‹ ã®ã‚ã‚‹è¨˜è¿°ã®ã¿ã‚’æ—¥æœ¬èªã§ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚",
        height=80,
    )
    user_prompt_tpl = st.text_area(
        "User Prompt ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆ{query}, {snippets} ã‚’åŸ‹ã‚è¾¼ã¿ï¼‰",
        value=(
            "ä»¥ä¸‹ã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã§å¾—ã‚‰ã‚ŒãŸãƒ’ãƒƒãƒˆã‚¹ãƒ‹ãƒšãƒƒãƒˆã§ã™ã€‚"
            "ã“ã®æƒ…å ±ã€ã®ã¿ã€‘ã‚’æ ¹æ‹ ã«ã€ã‚¯ã‚¨ãƒªã€{query}ã€ã«ã¤ã„ã¦è¦ç‚¹ã‚’ç®‡æ¡æ›¸ãâ†’çŸ­ã„ã¾ã¨ã‚ã®é †ã§æ•´ç†ã—ã¦ãã ã•ã„ã€‚"
            "\n\n# ãƒ’ãƒƒãƒˆã‚¹ãƒ‹ãƒšãƒƒãƒˆ\n{snippets}"
        ),
        height=140,
    )
    debug_mode = st.checkbox("ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º", value=False)

# ============== æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ  ==============
st.markdown("### ã‚¯ã‚¨ãƒª")
c1, c2 = st.columns([3,2])
with c1:
    query = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆç©ºç™½åŒºåˆ‡ã‚Šã§ AND / OR æŒ‡å®šï¼‰", value="")
with c2:
    bool_mode = st.radio("ãƒ¢ãƒ¼ãƒ‰", ["AND", "OR"], index=0, horizontal=True)

c3, c4, c5, c6 = st.columns(4)
with c3:
    use_regex = st.checkbox("æ­£è¦è¡¨ç¾", value=False)
with c4:
    case_sensitive = st.checkbox("å¤§æ–‡å­—å°æ–‡å­—ã‚’åŒºåˆ¥", value=False)
with c5:
    normalize_query = st.checkbox("æ—¥æœ¬èªã‚¹ãƒšãƒ¼ã‚¹æ­£è¦åŒ–ï¼ˆæ¨å¥¨ï¼‰", value=True)
with c6:
    norm_body = st.checkbox("æœ¬æ–‡ã‚‚æ­£è¦åŒ–ã—ã¦æ¤œç´¢", value=True, help="å–ã‚Šè¾¼ã¿æ™‚ã«æ­£è¦åŒ–ã—ã¦ã„ãªã„ã‚³ãƒ¼ãƒ‘ã‚¹å‘ã‘")

go = st.button("æ¤œç´¢ã‚’å®Ÿè¡Œ", type="primary")

# ============== æ¤œç´¢ãƒ­ã‚¸ãƒƒã‚¯ ==============
def compile_terms(q: str, use_regex: bool, case_sensitive: bool) -> List[re.Pattern]:
    if normalize_query:
        q = normalize_ja_text(q)
    terms = [t for t in q.split() if t]
    if not terms:
        return []
    flags = 0 if case_sensitive else re.IGNORECASE
    pats = []
    for t in terms:
        if use_regex:
            try:
                pats.append(re.compile(t, flags))
            except re.error:
                pats.append(re.compile(re.escape(t), flags))
        else:
            pats.append(re.compile(re.escape(t), flags))
    return pats

def _local_summary(labelled_snips: List[str], max_sent: int = 10) -> str:
    text = "\n\n".join(labelled_snips)
    text = re.sub(r"(?m)^---\s*$", "", text)
    text = re.sub(r"(?m)^#\s*Source:.*$", "", text)
    text = re.sub(r"<[^>]+>", "", text)
    parts = re.split(r"[ã€‚ï¼.!?ï¼ï¼Ÿ]\s*|\n+", text)
    uniq, out = set(), []
    for p in parts:
        p = (p or "").strip()
        if len(p) < 6 or p in uniq:
            continue
        uniq.add(p)
        out.append(f"ãƒ»{p}")
        if len(out) >= max_sent:
            break
    if not out:
        return "ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«æŠ½å‡ºã‚µãƒãƒªï¼šè¦ç´„ã§ãã‚‹æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼‰"
    short_base = parts[0] if parts else ""
    short = short_base[:120] + ("â€¦" if len(short_base) > 120 else "")
    return "### ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«æŠ½å‡ºã‚µãƒãƒªï¼‰\n" + "\n".join(out) + f"\n\nâ€” çŸ­ã„ã¾ã¨ã‚: {short}"

def _fit_to_budget(snips: List[str], *, model: str, sys_prompt: str, user_prefix: str,
                   want_output: int, context_limit: int, safety_margin: int) -> List[str]:
    while True:
        toks = count_tokens(sys_prompt, model) + count_tokens(user_prefix, model)
        toks += sum(count_tokens(s, model) for s in snips)
        need = toks + want_output + safety_margin
        if need <= context_limit or not snips:
            break
        snips = snips[:-1]
    if snips:
        budget = context_limit - (count_tokens(sys_prompt, model) + count_tokens(user_prefix, model) + want_output + safety_margin)
        budget = max(500, budget)
        snips = [s if count_tokens(s, model) <= budget else truncate_by_tokens(s, budget, model) for s in snips]
    return snips

def _openai_summary(*, model: str, temperature: float, max_tokens: int,
                    sys_prompt: str, user_prompt: str, api_key: str) -> str:
    if not (_HAS_OPENAI and api_key):
        raise RuntimeError("OpenAIæœªè¨­å®š")
    client = OpenAI(api_key=api_key)
    if is_gpt5(model):
        resp = client.responses.create(
            model=model,
            input=[{"role": "system", "content": sys_prompt.strip()},
                   {"role": "user", "content": user_prompt}],
            temperature=float(temperature),
            max_output_tokens=int(max_tokens),
        )
        try:
            return resp.output_text or ""
        except Exception:
            out = getattr(resp, "output", None)
            if out:
                for item in out:
                    if getattr(item, "type", "") == "message":
                        for c in getattr(item, "content", []) or []:
                            t = getattr(c, "text", None)
                            if isinstance(t, str) and t.strip():
                                return t
                    t = getattr(item, "text", None)
                    if isinstance(t, str) and t.strip():
                        return t
            return ""
    else:
        resp = client.chat.completions.create(
            model=model,
            temperature=float(temperature),
            max_tokens=int(max_tokens),
            messages=[
                {"role": "system", "content": sys_prompt.strip()},
                {"role": "user", "content": user_prompt},
            ],
        )
        try:
            return resp.choices[0].message.content or ""
        except Exception:
            return ""

# ============== å®Ÿè¡Œ ==============
if go:
    try:
        if not sel_shards:
            st.warning("å°‘ãªãã¨ã‚‚1ã¤ã®ã‚·ãƒ£ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
            st.stop()

        pats = compile_terms(query, use_regex=use_regex, case_sensitive=case_sensitive)
        if not pats:
            st.warning("æ¤œç´¢èªãŒç©ºã§ã™ã€‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            st.stop()

        rows: List[Dict[str,Any]] = []
        total_scanned = 0

        for sid in sel_shards:
            meta_path = base_dir / sid / "meta.jsonl"
            if not meta_path.exists():
                st.warning(f"{meta_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                continue
            for obj in iter_jsonl(meta_path):
                total_scanned += 1
                yr = obj.get("year", None)
                if isinstance(yr, int):
                    if year_min and yr < year_min: continue
                    if year_max and year_max < 9999 and yr > year_max: continue
                if file_filter and file_filter.lower() not in str(obj.get("file","")).lower():
                    continue

                text = str(obj.get("text",""))
                text_for_match = normalize_ja_text(text) if norm_body else text

                ok = all(p.search(text_for_match) for p in pats) if bool_mode == "AND" \
                     else any(p.search(text_for_match) for p in pats)
                if not ok:
                    continue

                score = sum(len(list(p.finditer(text_for_match))) for p in pats)
                rows.append({
                    "file": obj.get("file"),
                    "year": obj.get("year"),
                    "page": obj.get("page"),
                    "shard_id": obj.get("shard_id", sid),
                    "chunk_id": obj.get("chunk_id"),
                    "chunk_index": obj.get("chunk_index"),
                    "score": int(score),
                    "text": make_snippet(text, pats, total_len=int(snippet_len)),
                })

                if len(rows) >= int(max_rows):
                    break
            if len(rows) >= int(max_rows):
                break

        if not rows:
            st.warning("ãƒ’ãƒƒãƒˆãªã—ã€‚æ¤œç´¢èªã‚„ãƒ•ã‚£ãƒ«ã‚¿ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
            st.stop()

        df = pd.DataFrame(rows).sort_values(["score","year","file","page"], ascending=[False, True, True, True])

        st.success(f"ãƒ’ãƒƒãƒˆ {len(df):,d} ä»¶ / èµ°æŸ» {total_scanned:,d} ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼ˆä¸Šä½ã®ã¿è¡¨ç¤ºï¼‰")

        show_order = [c for c in show_cols if c in df.columns]
        if not show_order:
            show_order = ["file","year","page","shard_id","score","text"]
        non_text_cols = [c for c in show_order if c != "text"]
        st.dataframe(df[non_text_cols], use_container_width=True, height=420)

        csv_bytes = df[show_order].to_csv(index=False).encode("utf-8-sig")
        st.download_button("ğŸ“¥ CSV ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv_bytes, file_name="keyword_hits.csv", mime="text/csv")

        # ============== ğŸ§  è‡ªå‹•è¦ç´„ï¼ˆã‚¹ãƒ”ãƒŠãƒ¼ä»˜ãï¼‰ ==============
        if gen_enabled:
            st.divider()
            st.subheader("ğŸ§  ç”Ÿæˆè¦ç´„ï¼ˆè‡ªå‹•ï¼‰")

            # ä¸Šä½ N ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’æ•´å½¢
            take_n = int(topn_snippets)
            selected = df.head(take_n).copy()
            labelled_snips: List[str] = []
            for _, r in selected.iterrows():
                src = f"{r.get('file')} p.{r.get('page')} (score={r.get('score')})"
                snip = strip_html(str(r.get("text","")))
                labelled_snips.append(f"---\n# Source: {src}\n{snip}")

            # 1å›æŠ•ã’ã«åã‚ã‚‹ï¼ˆè¶…éæ™‚ã¯æœ«å°¾ã‹ã‚‰æ¸›ã‚‰ã™/åˆ‡ã‚Šè©°ã‚ï¼‰
            model_hint = model
            context_limit, safety_margin = (128_000, 2_000) if is_gpt5(model) else (128_000, 1_000)
            user_prefix = user_prompt_tpl.replace("{snippets}", "").format(query=query, snippets="")
            fitted = _fit_to_budget(
                labelled_snips, model=model_hint, sys_prompt=sys_prompt, user_prefix=user_prefix,
                want_output=int(max_tokens), context_limit=context_limit, safety_margin=safety_margin
            )
            if not fitted:
                with st.spinner("ğŸ§© ãƒ­ãƒ¼ã‚«ãƒ«æŠ½å‡ºã‚µãƒãƒªã‚’ç”Ÿæˆä¸­â€¦"):
                    st.info("âš ï¸ å…¥åŠ›ãŒå¤§ãã™ãã‚‹ãŸã‚ã€ãƒ­ãƒ¼ã‚«ãƒ«æŠ½å‡ºã‚µãƒãƒªã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                    st.markdown(_local_summary(labelled_snips, max_sent=12))
            else:
                snippets_text = "\n\n".join(fitted)
                user_prompt = user_prompt_tpl.format(query=query, snippets=snippets_text)
                approx = count_tokens(user_prompt, model_hint) + count_tokens(sys_prompt, model_hint)
                st.caption(f"ï¼ˆæ¨å®šå…¥åŠ› ~{approx:,} tok / å‡ºåŠ›ä¸Šé™ {int(max_tokens):,} tok / ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ~{context_limit:,} tokï¼‰")

                try:
                    with st.spinner("ğŸ§  è¦ç´„ã‚’ç”Ÿæˆä¸­â€¦"):
                        out = _openai_summary(
                            model=model, temperature=float(temperature), max_tokens=int(max_tokens),
                            sys_prompt=sys_prompt, user_prompt=user_prompt, api_key=OPENAI_API_KEY
                        )
                    if not out or not str(out).strip():
                        with st.spinner("ğŸ§© ãƒ­ãƒ¼ã‚«ãƒ«æŠ½å‡ºã‚µãƒãƒªã‚’ç”Ÿæˆä¸­â€¦"):
                            st.info("âš ï¸ ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ãŒç©ºã ã£ãŸãŸã‚ã€ãƒ­ãƒ¼ã‚«ãƒ«æŠ½å‡ºã‚µãƒãƒªã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                            st.markdown(_local_summary(fitted, max_sent=12))
                    else:
                        st.markdown(str(out).strip())
                except Exception as e:
                    if debug_mode:
                        st.error(f"OpenAI ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}", icon="ğŸ›‘")
                        st.code("".join(traceback.format_exc()))
                    with st.spinner("ğŸ§© ãƒ­ãƒ¼ã‚«ãƒ«æŠ½å‡ºã‚µãƒãƒªã‚’ç”Ÿæˆä¸­â€¦"):
                        st.markdown(_local_summary(fitted, max_sent=12))

        # ============== ãƒ’ãƒƒãƒˆã‚¹ãƒ‹ãƒšãƒƒãƒˆï¼ˆæ—¢å®šã§ç•³ã‚€ï¼‰ ==============
        if "text" in show_order:
            st.divider()
            with st.expander("ãƒ’ãƒƒãƒˆã‚¹ãƒ‹ãƒšãƒƒãƒˆï¼ˆã‚¯ãƒªãƒƒã‚¯ã§å±•é–‹ï¼‰", expanded=False):
                for i, row in df.head(200).iterrows():
                    colA, colB = st.columns([4,1])
                    with colA:
                        st.markdown(
                            f"**{row.get('file')}**  year={row.get('year')}  p.{row.get('page')}  "
                            f"score={row.get('score')}",
                            help=row.get("chunk_id")
                        )
                        st.markdown(row.get("text",""), unsafe_allow_html=True)
                    with colB:
                        # ã¡ã‚‡ã£ã¨ã—ãŸã‚³ãƒ”ãƒ¼æ©Ÿèƒ½ï¼ˆJSï¼‰â€” å¤±æ•—ã—ã¦ã‚‚å‹•ä½œã«å½±éŸ¿ã—ãªã„
                        payload = json.dumps(str(row.get("file")), ensure_ascii=False)
                        html = f"""
                        <button id="cpy_{i}" style="
                            padding:6px 10px;border-radius:8px;border:1px solid #dadce0;
                            background:#fff;cursor:pointer;font-size:0.9rem;">ğŸ“‹ year/file ã‚’ã‚³ãƒ”ãƒ¼</button>
                        <script>
                          const b=document.getElementById("cpy_{i}");
                          if(b){{b.addEventListener("click",async()=>{{
                            try{{await navigator.clipboard.writeText({payload});
                              const o=b.innerText;b.innerText="âœ… ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸ";
                              setTimeout(()=>{{b.innerText=o}},1200);
                            }}catch(e){{alert("ã‚³ãƒ”ãƒ¼ã«å¤±æ•—: "+e)}}
                          }})}}
                        </script>
                        """
                        st.components.v1.html(html, height=38)

    except Exception:
        st.error("æ¤œç´¢å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚", icon="ğŸ›‘")
        if debug_mode:
            st.code("".join(traceback.format_exc()))

else:
    st.info("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§æ¡ä»¶ã‚’è¨­å®šã—ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ã€æ¤œç´¢ã‚’å®Ÿè¡Œã€ã—ã¦ãã ã•ã„ã€‚")
