import os
from pathlib import Path
import streamlit as st
from dotenv import load_dotenv

from rag_utils import load_txt_files, split_text, EmbeddingStore, NumpyVectorDB, ProcessedFilesSimple

# ====== åˆæœŸåŒ– ======
load_dotenv()
st.set_page_config(page_title="Build KB from TXT (Structured Meta)", page_icon="ğŸ§±", layout="wide")
st.title("ğŸ§± Build Knowledge Base from `text/*.txt` (Structured Meta)")

text_dir = Path("text")
text_dir.mkdir(exist_ok=True)

# ====== ã‚ªãƒ—ã‚·ãƒ§ãƒ³ UI ======
with st.expander("ğŸ“¥ ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š", expanded=True):
    backend = st.radio("åŸ‹ã‚è¾¼ã¿ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰", ["local", "openai"], index=1)
    chunk_size = st.slider("ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆæ–‡å­—æ•°ï¼‰", 300, 2000, 900, 50)
    overlap = st.slider("ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ï¼ˆæ–‡å­—æ•°ï¼‰", 0, 400, 150, 10)
    batch_size = st.slider("åŸ‹ã‚è¾¼ã¿ãƒãƒƒãƒã‚µã‚¤ã‚º", 8, 256, 64, 8)
    reset = st.checkbox("æ—¢å­˜ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’åˆæœŸåŒ–ï¼ˆä½œã‚Šç›´ã™ï¼‰", value=False)
    skip_done = st.checkbox("å‰å›å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã§åˆ¤å®šï¼‰", value=True)

# ====== ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª ======
store_name = "openai" if backend == "openai" else "local"
vs_dir = Path("vectorstore") / store_name
vs_dir.mkdir(parents=True, exist_ok=True)

# ====== å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç† ======
pstore = ProcessedFilesSimple(vs_dir / "processed_files.json")

# ====== å®Ÿè¡Œãƒœã‚¿ãƒ³ ======
if st.button("ğŸ”¨ TXT ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦ä¿å­˜", type="primary"):
    files = load_txt_files(text_dir)  # -> [(fname, text)]
    if not files:
        st.warning("`text/` ã« .txt ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()

    if store_name == "openai" and not os.getenv("OPENAI_API_KEY"):
        st.error("OPENAI_API_KEY ãŒ .env ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.stop()

    estore = EmbeddingStore(backend=store_name)
    vdb = NumpyVectorDB(vs_dir)

    if reset:
        vdb.reset()
        pstore.reset()
        st.info(f"æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸï¼š{vs_dir}")

    to_process = []
    skipped = 0
    for fname, text in files:
        if skip_done and pstore.is_done(fname):
            skipped += 1
            continue
        chs = split_text(text, chunk_size=chunk_size, overlap=overlap)  # [(chunk, start, end)]
        if chs:
            to_process.append((fname, chs))

    if not to_process:
        st.success(f"å‡¦ç†å¯¾è±¡ã¯ã‚ã‚Šã¾ã›ã‚“ï¼ˆã‚¹ã‚­ãƒƒãƒ— {skipped} ä»¶ï¼‰ã€‚")
        st.stop()

    total_chunks = sum(len(chs) for _, chs in to_process)
    st.write(f"å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: **{len(to_process)}** ä»¶ / ãƒãƒ£ãƒ³ã‚¯ç·æ•°: **{total_chunks}**")

    prog = st.progress(0.0)
    done_chunks = 0

    for fname, chs in to_process:
        texts = []
        meta_items = []
        for idx, (chunk, start, end) in enumerate(chs):
            chunk_id = f"{fname}#p1#{idx}"
            meta_items.append({
                "file": fname,
                "page": 1,
                "chunk_id": chunk_id,
                "chunk_index": idx,
                "text": chunk,
                "span_start": start,
                "span_end": end,
            })
            texts.append(chunk)

        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i + batch_size]
            batch_meta = meta_items[i:i + batch_size]
            embs = estore.embed(batch_texts, batch_size=batch_size)
            vdb.add(embs, batch_meta)
            done_chunks += len(batch_texts)
            prog.progress(done_chunks / total_chunks)

        pstore.mark_done(fname)

    st.success(f"âœ… ãƒ™ã‚¯ãƒˆãƒ«åŒ–å®Œäº†: {total_chunks} ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜ã—ã¾ã—ãŸ ({vs_dir})")
    st.caption("meta.jsonl ã«ã¯ file/page/chunk_id/chunk_index/span_start/span_end ã‚’å«ã¿ã¾ã™ã€‚")
