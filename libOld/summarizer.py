# lib/summarizer.py
from __future__ import annotations
from typing import List
import re
import streamlit as st
from openai import OpenAI

from lib.openai_utils import (
    is_gpt5, count_tokens, truncate_by_tokens,
    responses_generate, responses_text,
    chat_complete_safely, extract_text_from_chat,
)
from lib.text_utils import strip_html

_SUM_RES_KEY = "kw_last_summary_result"
_SUM_ERR_KEY = "kw_last_summary_error"

# ---- ãƒ­ãƒ¼ã‚«ãƒ«æŠ½å‡ºã‚µãƒãƒªï¼ˆOpenAIä¸ä½¿ç”¨ã®ä¿é™ºï¼‰ -------------------
def _local_summary(labelled_snips: List[str], max_sent: int = 10) -> str:
    text = "\n\n".join(labelled_snips)
    text = re.sub(r"(?m)^---\s*$", "", text)
    text = re.sub(r"(?m)^#\s*Source:.*$", "", text)
    text = re.sub(r"<[^>]+>", "", text)
    parts = re.split(r"[ã€‚ï¼.!?ï¼ï¼Ÿ]\s*|\n+", text)
    uniq, out = set(), []
    for p in parts:
        p = p.strip()
        if len(p) < 6 or p in uniq:
            continue
        uniq.add(p)
        out.append(f"ãƒ»{p}")
        if len(out) >= max_sent:
            break
    if not out:
        return "ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«æŠ½å‡ºã‚µãƒãƒªï¼šè¦ç´„ã§ãã‚‹æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼‰"
    short_base = parts[0] if parts else ""
    short = short_base[:120] + ("â€¦" if len(short_base) > 120 else "")
    return "### ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«æŠ½å‡ºã‚µãƒãƒªï¼‰\n" + "\n".join(out) + f"\n\nâ€” çŸ­ã„ã¾ã¨ã‚: {short}"

# ---- äºˆç®—ã«åã¾ã‚‹ã‚ˆã†ã«ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’å‰Šã‚‹/åˆ‡ã‚Šè©°ã‚ã‚‹ï¼ˆ1å›æŠ•ã’ä¿è¨¼ï¼‰ ---
def _fit_to_budget(snips: List[str], *, model: str, sys_prompt: str, user_prefix: str,
                   want_output: int, context_limit: int, safety_margin: int) -> List[str]:
    # ã§ãã‚‹ã ã‘ä¿æŒã—ã¤ã¤ã€è¶…éã—ãŸã‚‰æœ«å°¾ã‹ã‚‰å‰Šã‚‹
    while True:
        toks = count_tokens(sys_prompt, model) + count_tokens(user_prefix, model)
        toks += sum(count_tokens(s, model) for s in snips)
        need = toks + want_output + safety_margin
        if need <= context_limit or not snips:
            break
        snips = snips[:-1]
    # 1è¦ç´ ãŒå·¨å¤§ãªã‚‰åˆ‡ã‚Šè©°ã‚
    if snips:
        budget = context_limit - (count_tokens(sys_prompt, model) + count_tokens(user_prefix, model) + want_output + safety_margin)
        budget = max(500, budget)
        snips = [s if count_tokens(s, model) <= budget else truncate_by_tokens(s, budget, model) for s in snips]
    return snips

# ---- ãƒ¡ã‚¤ãƒ³ï¼šãã®å ´ã§ç¢ºå®Ÿã«æç”»ã™ã‚‹è¶…ã‚·ãƒ³ãƒ—ãƒ«å®Ÿè£… -------------------
def run_summary(
    *, df, model: str, temperature: float, max_tokens: int,
    topn_snippets: int, auto_batch: bool, verbose_log: bool, debug_mode: bool,
    sys_prompt: str, user_prompt_tpl: str, OPENAI_API_KEY: str, query: str
):
    st.divider()
    st.subheader("ğŸ§  ç”Ÿæˆè¦ç´„ï¼ˆãƒ¯ãƒ³ã‚·ãƒ§ãƒƒãƒˆãƒ»ç¢ºå®Ÿè¡¨ç¤ºï¼‰")

    # ç›´è¿‘çµæœã®è¡¨ç¤ºã¨ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³ï¼ˆä»»æ„ï¼‰
    if _SUM_RES_KEY in st.session_state:
        with st.expander("ç›´è¿‘ã®è¦ç´„çµæœï¼ˆé–‹é–‰å¯ï¼‰", expanded=False):
            st.markdown(st.session_state[_SUM_RES_KEY])
        cols = st.columns([1,4])
        with cols[0]:
            if st.button("ğŸ§¹ è¦ç´„çµæœã‚’ã‚¯ãƒªã‚¢", key="clear_last_summary"):
                st.session_state.pop(_SUM_RES_KEY, None)
                st.session_state.pop(_SUM_ERR_KEY, None)

    # ---- ã‚¹ãƒ‹ãƒšãƒƒãƒˆæ•´å½¢ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ï¼‰----
    take_n = int(topn_snippets)
    selected = df.head(take_n).copy()
    labelled_snips: List[str] = []
    for _, r in selected.iterrows():
        src = f"{r.get('file')} p.{r.get('page')} (score={r.get('score')})"
        snip = strip_html(str(r.get("text","")))
        labelled_snips.append(f"---\n# Source: {src}\n{snip}")

    # å®Ÿè¡Œãƒœã‚¿ãƒ³ï¼ˆãƒ•ã‚©ãƒ¼ãƒ ã‚„ãƒã‚§ãƒƒã‚¯ã¯ä½¿ã‚ãªã„ï¼šå†å®Ÿè¡Œã®å‰¯ä½œç”¨ã‚’æ’é™¤ï¼‰
    run = st.button("ğŸ§  è¦ç´„ã‚’å®Ÿè¡Œï¼ˆå³æ™‚ï¼‰", type="primary", use_container_width=True, key="run_summary_now")

    # æŠ¼ã•ã‚Œãªã‘ã‚Œã°ä½•ã‚‚ã—ãªã„
    if not run:
        st.info("ã€ğŸ§  è¦ç´„ã‚’å®Ÿè¡Œï¼ˆå³æ™‚ï¼‰ã€ã‚’æŠ¼ã™ã¨ã€ã“ã®ãƒšãƒ¼ã‚¸ã®å®Ÿè¡Œå†…ã§è¦ç´„ã‚’ç”Ÿæˆã—ã¦ä¸‹ã«è¡¨ç¤ºã—ã¾ã™ã€‚")
        return

    # ---- ã“ã“ã‹ã‚‰â€œåŒã˜å®Ÿè¡Œå†…â€ã§ç”Ÿæˆãƒ»æç”» -------------------------
    model_hint = model
    context_limit, safety_margin = (128_000, 2_000) if is_gpt5(model) else (128_000, 1_000)
    user_prefix = user_prompt_tpl.replace("{snippets}", "").format(query=query, snippets="")

    fitted_snips = _fit_to_budget(
        labelled_snips, model=model_hint, sys_prompt=sys_prompt, user_prefix=user_prefix,
        want_output=int(max_tokens), context_limit=context_limit, safety_margin=safety_margin
    )
    if not fitted_snips:
        # ãã‚Œã§ã‚‚ç„¡ç†ãªã‚‰ãƒ­ãƒ¼ã‚«ãƒ«æŠ½å‡º
        out_text = _local_summary(labelled_snips, max_sent=12)
        st.session_state[_SUM_RES_KEY] = out_text
        st.markdown(out_text)
        return

    snippets_text = "\n\n".join(fitted_snips)
    user_prompt = user_prompt_tpl.format(query=query, snippets=snippets_text)

    approx = count_tokens(user_prompt, model_hint) + count_tokens(sys_prompt, model_hint)
    st.caption(f"ï¼ˆæ¨å®šå…¥åŠ› ~{approx:,} tok / å‡ºåŠ›ä¸Šé™ {int(max_tokens):,} tok / ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ~{context_limit:,} tokï¼‰")

    # ---- OpenAI å®Ÿè¡Œï¼ˆå¤±æ•—æ™‚ã¯å¿…ãšãƒ­ãƒ¼ã‚«ãƒ«æŠ½å‡ºã‚’è¡¨ç¤ºï¼‰ -------------
    try:
        if not OPENAI_API_KEY:
            raise RuntimeError("OPENAI_API_KEY ãŒæœªè¨­å®šã§ã™ã€‚")

        client = OpenAI(api_key=OPENAI_API_KEY)

        with st.spinner("è¦ç´„ã‚’ç”Ÿæˆä¸­â€¦"):
            if is_gpt5(model):
                resp = responses_generate(
                    client, model=model, temperature=float(temperature),
                    max_output_tokens=int(max_tokens), system_prompt=sys_prompt,
                    user_prompt=user_prompt
                )
                out = responses_text(resp)
            else:
                resp = chat_complete_safely(
                    client, model=model, temperature=float(temperature),
                    limit_tokens=int(max_tokens), system_prompt=sys_prompt,
                    user_prompt=user_prompt
                )
                out = extract_text_from_chat(resp)

        if not out or not str(out).strip():
            raise RuntimeError("ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ãŒç©ºã§ã—ãŸã€‚")

        out_text = str(out).strip()
        st.session_state[_SUM_RES_KEY] = out_text  # æ¬¡å›ä»¥é™ã‚‚æ®‹ã™
        st.markdown(out_text)

    except Exception as e:
        if debug_mode:
            st.error(f"OpenAI ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}", icon="ğŸ›‘")
        # ä¿é™ºï¼šå¿…ãšãƒ­ãƒ¼ã‚«ãƒ«æŠ½å‡ºã‚’å‡ºã™
        out_text = _local_summary(fitted_snips, max_sent=12)
        st.session_state[_SUM_RES_KEY] = out_text
        st.session_state[_SUM_ERR_KEY] = f"{type(e).__name__}: {e}"
        st.markdown(out_text)
